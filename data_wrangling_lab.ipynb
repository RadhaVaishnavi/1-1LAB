{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAagTh8A-5Nj"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "fields = [\"Name\", \"Age\", \"Class\"]\n",
        "data = {\"Name\": \"John\", \"Age\": 20, \"Class\": \"12A\"}\n",
        "\n",
        "with open(\"students.csv\", \"w\", newline='') as file_writer:\n",
        "    writer = csv.DictWriter(file_writer, fieldnames=fields)\n",
        "    writer.writeheader()\n",
        "    writer.writerow(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Define multiple lists\n",
        "names = [\"John\", \"Alice\", \"Bob\", \"Diana\"]\n",
        "ages = [20, 18, 19, 21]\n",
        "classes = [\"12A\", \"12B\", \"12A\", \"12C\"]\n",
        "\n",
        "# Write data to CSV\n",
        "with open(\"students.csv\", \"w\", newline='') as file_writer:\n",
        "    # Define field names\n",
        "    fields = [\"Name\", \"Age\", \"Class\"]\n",
        "\n",
        "    # Create a CSV writer object\n",
        "    writer = csv.DictWriter(file_writer, fieldnames=fields)\n",
        "\n",
        "    # Write the header row\n",
        "    writer.writeheader()\n",
        "\n",
        "    # Combine data from multiple lists and write rows\n",
        "    for name, age, class_ in zip(names, ages, classes):\n",
        "        writer.writerow({\"Name\": name, \"Age\": age, \"Class\": class_})\n",
        "\n",
        "print(\"Data written to students.csv successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNy6CGKsVy_K",
        "outputId": "9554c0e5-5fe9-4ea1-8efa-f8a90104f960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data written to students.csv successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def main():\n",
        "    # Open the CSV file\n",
        "    try:\n",
        "        with open('students.csv', newline='') as csv_file:\n",
        "            csv_read = csv.reader(csv_file, delimiter=',')\n",
        "\n",
        "            # Read and display each row\n",
        "            for row in csv_read:\n",
        "                print(row)\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: The file 'students.csv' was not found. Please ensure the file is in the correct location.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf7MYdUZ_WaY",
        "outputId": "aa6585e8-aaa8-4bca-a7a9-a0277c087dd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Name', 'Age', 'Class']\n",
            "['John', '20', '12A']\n",
            "['Alice', '18', '12B']\n",
            "['Bob', '19', '12A']\n",
            "['Diana', '21', '12C']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def read_csv_as_dict():\n",
        "    filename = \"students.csv\"  # File name\n",
        "\n",
        "    try:\n",
        "        # Open the CSV file\n",
        "        with open(filename, mode=\"r\") as file_reader:\n",
        "            # Read the CSV file as a dictionary\n",
        "            csv_reader = csv.DictReader(file_reader)\n",
        "\n",
        "            # Loop through and display each row as a dictionary\n",
        "            for row in csv_reader:\n",
        "                print(row)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{filename}' was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Call the function to read and display the CSV contents\n",
        "read_csv_as_dict()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xklWcZYSZ24M",
        "outputId": "cbf3779d-3a16-444f-97cb-056a4dfeb303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Name': 'John', 'Age': '20', 'Class': '12A'}\n",
            "{'Name': 'Alice', 'Age': '18', 'Class': '12B'}\n",
            "{'Name': 'Bob', 'Age': '19', 'Class': '12A'}\n",
            "{'Name': 'Diana', 'Age': '21', 'Class': '12C'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import json\n",
        "\n",
        "def read_csv_as_dict(filename):\n",
        "    students_data = []\n",
        "\n",
        "    try:\n",
        "        # Open the CSV file\n",
        "        with open(filename, mode=\"r\") as file_reader:\n",
        "            csv_reader = csv.DictReader(file_reader)\n",
        "\n",
        "            # Convert each row to a dictionary and append to the list\n",
        "            for row in csv_reader:\n",
        "                students_data.append(row)\n",
        "\n",
        "        return students_data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{filename}' was not found.\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return []\n",
        "\n",
        "def convert_to_json(data):\n",
        "    try:\n",
        "        # Sort dictionary objects by key and convert to JSON with an indent level of 4\n",
        "        json_data = json.dumps(data, indent=4, sort_keys=True)\n",
        "        print(\"JSON Data:\")\n",
        "        print(json_data)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during conversion: {e}\")\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    filename = \"students.csv\"  # File name\n",
        "\n",
        "    # Read the CSV file and get data as a list of dictionaries\n",
        "    students_data = read_csv_as_dict(filename)\n",
        "\n",
        "    if students_data:\n",
        "        # Convert to JSON and display\n",
        "        convert_to_json(students_data)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DSE5UQFcU4b",
        "outputId": "59b055e6-d247-4bfe-8fc9-2f5e0a109bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON Data:\n",
            "[\n",
            "    {\n",
            "        \"Age\": \"20\",\n",
            "        \"Class\": \"12A\",\n",
            "        \"Name\": \"John\"\n",
            "    },\n",
            "    {\n",
            "        \"Age\": \"18\",\n",
            "        \"Class\": \"12B\",\n",
            "        \"Name\": \"Alice\"\n",
            "    },\n",
            "    {\n",
            "        \"Age\": \"19\",\n",
            "        \"Class\": \"12A\",\n",
            "        \"Name\": \"Bob\"\n",
            "    },\n",
            "    {\n",
            "        \"Age\": \"21\",\n",
            "        \"Class\": \"12C\",\n",
            "        \"Name\": \"Diana\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def read_xml_file(filename):\n",
        "    try:\n",
        "        # Parse the XML file\n",
        "        tree = ET.parse(filename)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        # Print the root element and its children\n",
        "        print(f\"Root Element: {root.tag}\")\n",
        "        print(\"\\nChild Elements:\")\n",
        "        for child in root:\n",
        "            print(f\"Tag: {child.tag}, Attributes: {child.attrib}\")\n",
        "            for subchild in child:\n",
        "                print(f\"  Subtag: {subchild.tag}, Text: {subchild.text}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{filename}' was not found.\")\n",
        "    except ET.ParseError as e:\n",
        "        print(f\"Error: Failed to parse the XML file. Details: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Specify the XML file name\n",
        "filename = \"students.xml\"\n",
        "\n",
        "# Call the function to read and display the XML contents\n",
        "read_xml_file(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVMzl_Cmg0GY",
        "outputId": "74bb9847-cb2c-4206-c5f5-292b7e1ac47d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Element: students\n",
            "\n",
            "Child Elements:\n",
            "Tag: student, Attributes: {'id': '1'}\n",
            "  Subtag: name, Text: John\n",
            "  Subtag: age, Text: 20\n",
            "  Subtag: class, Text: 12A\n",
            "Tag: student, Attributes: {'id': '2'}\n",
            "  Subtag: name, Text: Alice\n",
            "  Subtag: age, Text: 18\n",
            "  Subtag: class, Text: 12B\n",
            "Tag: student, Attributes: {'id': '3'}\n",
            "  Subtag: name, Text: Bob\n",
            "  Subtag: age, Text: 19\n",
            "  Subtag: class, Text: 12A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas openpyxl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3Uc8C2IiyJD",
        "outputId": "dcb694f0-f7dc-4bf6-d5d5-00f31ce7c8ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def process_excel_data(filename):\n",
        "    try:\n",
        "        # Import the Excel file\n",
        "        data = pd.read_excel(filename)\n",
        "\n",
        "        # Display the first few rows of the data\n",
        "        print(\"First 5 rows of the data:\")\n",
        "        print(data.head())\n",
        "\n",
        "        # Display basic information about the data\n",
        "        print(\"\\nData Information:\")\n",
        "        print(data.info())\n",
        "\n",
        "        # Check for missing values\n",
        "        print(\"\\nMissing Values:\")\n",
        "        print(data.isnull().sum())\n",
        "\n",
        "        # Handle missing data (e.g., fill with mean or drop rows/columns)\n",
        "        data_cleaned = data.dropna()  # Drop rows with missing values\n",
        "        print(\"\\nData after handling missing values:\")\n",
        "        print(data_cleaned.head())\n",
        "\n",
        "        # Perform basic analysis (e.g., grouping or summarizing data)\n",
        "        # Example: Count child labor cases by region\n",
        "        if 'Region' in data_cleaned.columns and 'Child Labor Cases' in data_cleaned.columns:\n",
        "            region_summary = data_cleaned.groupby('Region')['Child Labor Cases'].sum()\n",
        "            print(\"\\nChild Labor Cases by Region:\")\n",
        "            print(region_summary)\n",
        "\n",
        "        # Export the processed DataFrame back to an Excel file\n",
        "        output_file = \"processed_data.xlsx\"\n",
        "        data_cleaned.to_excel(output_file, index=False)\n",
        "        print(f\"\\nProcessed data has been saved to '{output_file}'.\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{filename}' was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Specify the filename\n",
        "filename = \"Child_Labour_Marriage.xlsx\"\n",
        "\n",
        "# Process the Excel file\n",
        "process_excel_data(filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcIsEk_fi118",
        "outputId": "593e6957-d8f3-4895-d320-ee7021673fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the data:\n",
            "      Country   Female Married by 15  Female Married by 18  Reference year  \\\n",
            "0  Afghanistan                   4.0                  28.0          2017.0   \n",
            "1      Albania                   1.0                  12.0          2018.0   \n",
            "2      Algeria                   0.0                   3.0          2013.0   \n",
            "3      Andorra                   NaN                   NaN             NaN   \n",
            "4       Angola                   8.0                  30.0          2016.0   \n",
            "\n",
            "    Data source  Male Married by 18  Male Reference year Data source.1  \n",
            "0  ALCS 2016-17                 7.0               2015.0      DHS 2015  \n",
            "1   DHS 2017-18                 1.0               2018.0   DHS 2017-18  \n",
            "2  MICS 2012-13                 NaN                  NaN           NaN  \n",
            "3           NaN                 NaN                  NaN           NaN  \n",
            "4   DHS 2015-16                 6.0               2016.0   DHS 2015-16  \n",
            "\n",
            "Data Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 202 entries, 0 to 201\n",
            "Data columns (total 8 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Country               202 non-null    object \n",
            " 1   Female Married by 15  128 non-null    float64\n",
            " 2   Female Married by 18  128 non-null    float64\n",
            " 3   Reference year        128 non-null    float64\n",
            " 4   Data source           128 non-null    object \n",
            " 5   Male Married by 18    95 non-null     float64\n",
            " 6   Male Reference year   95 non-null     float64\n",
            " 7   Data source.1         95 non-null     object \n",
            "dtypes: float64(5), object(3)\n",
            "memory usage: 12.8+ KB\n",
            "None\n",
            "\n",
            "Missing Values:\n",
            "Country                   0\n",
            "Female Married by 15     74\n",
            "Female Married by 18     74\n",
            "Reference year           74\n",
            "Data source              74\n",
            "Male Married by 18      107\n",
            "Male Reference year     107\n",
            "Data source.1           107\n",
            "dtype: int64\n",
            "\n",
            "Data after handling missing values:\n",
            "       Country   Female Married by 15  Female Married by 18  Reference year  \\\n",
            "0   Afghanistan                   4.0                  28.0          2017.0   \n",
            "1       Albania                   1.0                  12.0          2018.0   \n",
            "4        Angola                   8.0                  30.0          2016.0   \n",
            "8       Armenia                   0.0                   5.0          2016.0   \n",
            "11   Azerbaijan                   2.0                  11.0          2011.0   \n",
            "\n",
            "     Data source  Male Married by 18  Male Reference year Data source.1  \n",
            "0   ALCS 2016-17                 7.0               2015.0      DHS 2015  \n",
            "1    DHS 2017-18                 1.0               2018.0   DHS 2017-18  \n",
            "4    DHS 2015-16                 6.0               2016.0   DHS 2015-16  \n",
            "8    DHS 2015-16                 0.0               2016.0   DHS 2015-16  \n",
            "11      DHS 2011                 0.0               2006.0      DHS 2006  \n",
            "\n",
            "Processed data has been saved to 'processed_data.xlsx'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def check_dtypes(filename):\n",
        "    try:\n",
        "        # Import the Excel file into a Pandas DataFrame\n",
        "        data = pd.read_excel(filename)\n",
        "\n",
        "        # Display the data types of each column\n",
        "        print(\"\\nData Types of Columns:\")\n",
        "        print(data.dtypes)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{filename}' was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Specify the filename\n",
        "filename = \"Child_Labour_Marriage.xlsx\"\n",
        "\n",
        "# Call the function to check data types\n",
        "check_dtypes(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p85GaBsqDx_T",
        "outputId": "197f0e98-eead-44a3-be71-68db4573faa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data Types of Columns:\n",
            "Country                  object\n",
            "Female Married by 15    float64\n",
            "Female Married by 18    float64\n",
            "Reference year          float64\n",
            "Data source              object\n",
            "Male Married by 18      float64\n",
            "Male Reference year     float64\n",
            "Data source.1            object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def display_last_rows(filename):\n",
        "    try:\n",
        "        # Import the Excel file into a Pandas DataFrame\n",
        "        data = pd.read_excel(filename)\n",
        "\n",
        "        # Display the last 10 rows of the DataFrame\n",
        "        print(\"Last 10 rows of the data:\")\n",
        "        print(data.tail(10))  # Displays the last 10 rows\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{filename}' was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Specify the filename\n",
        "filename = \"Child_Labour_Marriage.xlsx\"\n",
        "\n",
        "# Call the function to import the Excel file and display the last 10 rows\n",
        "display_last_rows(filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uCW8wDUH_nx",
        "outputId": "beab5621-e11f-42c7-c81c-72f789f79a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last 10 rows of the data:\n",
            "                               Country   Female Married by 15  \\\n",
            "192         United Republic of Tanzania                   5.0   \n",
            "193                       United States                   NaN   \n",
            "194                             Uruguay                   1.0   \n",
            "195                          Uzbekistan                   0.0   \n",
            "196                             Vanuatu                   3.0   \n",
            "197  Venezuela (Bolivarian Republic of)                   NaN   \n",
            "198                            Viet Nam                   1.0   \n",
            "199                               Yemen                   9.0   \n",
            "200                              Zambia                   5.0   \n",
            "201                            Zimbabwe                   5.0   \n",
            "\n",
            "     Female Married by 18  Reference year  Data source  Male Married by 18  \\\n",
            "192                  31.0          2016.0  DHS 2015-16                 4.0   \n",
            "193                   NaN             NaN          NaN                 NaN   \n",
            "194                  25.0          2013.0    MICS 2013                 NaN   \n",
            "195                   7.0          2006.0    MICS 2006                 1.0   \n",
            "196                  21.0          2013.0     DHS 2013                 5.0   \n",
            "197                   NaN             NaN          NaN                 NaN   \n",
            "198                  11.0          2014.0    MICS 2014                 3.0   \n",
            "199                  32.0          2013.0     DHS 2013                 NaN   \n",
            "200                  29.0          2018.0     DHS 2018                 3.0   \n",
            "201                  34.0          2019.0    MICS 2019                 2.0   \n",
            "\n",
            "     Male Reference year Data source.1  \n",
            "192               2016.0   DHS 2015-16  \n",
            "193                  NaN           NaN  \n",
            "194                  NaN           NaN  \n",
            "195               2002.0      DHS 2002  \n",
            "196               2013.0      DHS 2013  \n",
            "197                  NaN           NaN  \n",
            "198               2005.0      AIS 2005  \n",
            "199                  NaN           NaN  \n",
            "200               2018.0      DHS 2018  \n",
            "201               2019.0     MICS 2019  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas openpyxl numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-8ARrB8LnPW",
        "outputId": "6e9f41c3-54fd-4c41-95fc-15786ea35a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def insert_column_with_nan(filename, output):\n",
        "    try:\n",
        "        # Load the Excel file into a DataFrame\n",
        "        data = pd.read_excel(filename)\n",
        "\n",
        "        # Insert a column in the 6th position (index 5)\n",
        "        data.insert(5, \"New_Col\", np.nan)\n",
        "\n",
        "        # Display the updated DataFrame\n",
        "        print(\"Updated DataFrame with the new column:\")\n",
        "        print(data.head())\n",
        "\n",
        "        # Save the updated DataFrame back to a new Excel file\n",
        "        data.to_excel(output, index=False)\n",
        "        print(f\"\\nUpdated file has been saved as '{output}'.\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{filename}' was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# File names\n",
        "input = \"Child_Labour_Marriage.xlsx\"\n",
        "output = \"updated_child_labour_marriage_data.xlsx\"\n",
        "\n",
        "# Call the function\n",
        "insert_column_with_nan(input, output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwfwfXg0F1XR",
        "outputId": "9f8c3f9a-373e-4989-a1e0-e1ea574f76e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated DataFrame with the new column:\n",
            "      Country   Female Married by 15  Female Married by 18  Reference year  \\\n",
            "0  Afghanistan                   4.0                  28.0          2017.0   \n",
            "1      Albania                   1.0                  12.0          2018.0   \n",
            "2      Algeria                   0.0                   3.0          2013.0   \n",
            "3      Andorra                   NaN                   NaN             NaN   \n",
            "4       Angola                   8.0                  30.0          2016.0   \n",
            "\n",
            "    Data source  New_Col  Male Married by 18  Male Reference year  \\\n",
            "0  ALCS 2016-17      NaN                 7.0               2015.0   \n",
            "1   DHS 2017-18      NaN                 1.0               2018.0   \n",
            "2  MICS 2012-13      NaN                 NaN                  NaN   \n",
            "3           NaN      NaN                 NaN                  NaN   \n",
            "4   DHS 2015-16      NaN                 6.0               2016.0   \n",
            "\n",
            "  Data source.1  \n",
            "0      DHS 2015  \n",
            "1   DHS 2017-18  \n",
            "2           NaN  \n",
            "3           NaN  \n",
            "4   DHS 2015-16  \n",
            "\n",
            "Updated file has been saved as 'updated_child_labour_marriage_data.xlsx'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdfminer.six"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSBeBRm1Lj64",
        "outputId": "84c0d114-7194-4fab-ad64-ec5893198b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/5.6 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/5.6 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m5.4/5.6 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20240706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdfminer.high_level import extract_text\n",
        "from pdfminer.high_level import extract_pages\n",
        "from pdfminer.layout import LTTextContainer\n",
        "\n",
        "def parse_pdf_text(file_path):\n",
        "    try:\n",
        "        # Extract the plain text from the PDF\n",
        "        text = extract_text(file_path)\n",
        "\n",
        "        # Display the extracted text\n",
        "        print(\"Extracted Text:\")\n",
        "        print(text[:1000])  # Print first 1000 characters for preview\n",
        "\n",
        "        # Optionally save the extracted text to a file\n",
        "        with open(\"output_text.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
        "            text_file.write(text)\n",
        "        print(\"\\nExtracted text has been saved to 'output_text.txt'.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{file_path}' was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "def parse_pdf_layout(file_path):\n",
        "    try:\n",
        "        # Extract detailed layout information\n",
        "        print(\"Extracting detailed layout information:\")\n",
        "        for page_layout in extract_pages(file_path):\n",
        "            for element in page_layout:\n",
        "                if isinstance(element, LTTextContainer):\n",
        "                    print(element.get_text())\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{file_path}' was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Specify the path to the PDF file\n",
        "pdf_file_path = \"sample.pdf\"\n",
        "\n",
        "# Parse the PDF text\n",
        "parse_pdf_text(pdf_file_path)\n"
      ],
      "metadata": {
        "id": "LdjuLepxcJce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "237f64b7-6257-4b32-c12e-2f7611b21f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text:\n",
            "UNIT-V\n",
            "\n",
            "\fProviding the Basis for Universal Human Values and Ethical Human Conduct\n",
            "\n",
            "\fDefinitiveness of Ethical Human Conduct:\n",
            "1. Values (Mülya): Values are a part of our ethical conduct. They are the outcome of realization and \n",
            "understanding, which are always definite. As already mentioned, when I understand the reality correctly, and the \n",
            "underlying harmony at all levels of existence and my participation in it, I am able to perceive the universal human \n",
            "values as a part and parcel of this reality. My imaginations are now always in terms of the definite.\n",
            "2. Policy (Nïti): Having been convinced about the values and about the inherent harmony in the existence, I am \n",
            "able to develop an ethical sense in all my pursuits. I always think, behave and work towards nurturing this \n",
            "harmony. It leads us to adopt policies conducive to human welfare – conducive to enrichment, protection and \n",
            "right utilization of mind, body and wealth. This is an outcome of the definiteness of my desire, thought and \n",
            "\n",
            "\n",
            "Extracted text has been saved to 'output_text.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdfplumber pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLueYTxJeIgw",
        "outputId": "1b194d5e-3f4a-42bb-eecf-452d0a8c6a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Excel file into a DataFrame\n",
        "file_path = \"Child_Labour_Marriage.xlsx\"\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Display the data\n",
        "print(data)\n",
        "\n",
        "# Optionally save to a new file if modifications are made\n",
        "data.to_excel(\"processed_data.xlsx\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOu2XxshfNRE",
        "outputId": "c200902d-9540-440e-dd96-bb53b0408a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               Country   Female Married by 15  \\\n",
            "0                           Afghanistan                   4.0   \n",
            "1                               Albania                   1.0   \n",
            "2                               Algeria                   0.0   \n",
            "3                               Andorra                   NaN   \n",
            "4                                Angola                   8.0   \n",
            "..                                  ...                   ...   \n",
            "197  Venezuela (Bolivarian Republic of)                   NaN   \n",
            "198                            Viet Nam                   1.0   \n",
            "199                               Yemen                   9.0   \n",
            "200                              Zambia                   5.0   \n",
            "201                            Zimbabwe                   5.0   \n",
            "\n",
            "     Female Married by 18  Reference year   Data source  Male Married by 18  \\\n",
            "0                    28.0          2017.0  ALCS 2016-17                 7.0   \n",
            "1                    12.0          2018.0   DHS 2017-18                 1.0   \n",
            "2                     3.0          2013.0  MICS 2012-13                 NaN   \n",
            "3                     NaN             NaN           NaN                 NaN   \n",
            "4                    30.0          2016.0   DHS 2015-16                 6.0   \n",
            "..                    ...             ...           ...                 ...   \n",
            "197                   NaN             NaN           NaN                 NaN   \n",
            "198                  11.0          2014.0     MICS 2014                 3.0   \n",
            "199                  32.0          2013.0      DHS 2013                 NaN   \n",
            "200                  29.0          2018.0      DHS 2018                 3.0   \n",
            "201                  34.0          2019.0     MICS 2019                 2.0   \n",
            "\n",
            "     Male Reference year Data source.1  \n",
            "0                 2015.0      DHS 2015  \n",
            "1                 2018.0   DHS 2017-18  \n",
            "2                    NaN           NaN  \n",
            "3                    NaN           NaN  \n",
            "4                 2016.0   DHS 2015-16  \n",
            "..                   ...           ...  \n",
            "197                  NaN           NaN  \n",
            "198               2005.0      AIS 2005  \n",
            "199                  NaN           NaN  \n",
            "200               2018.0      DHS 2018  \n",
            "201               2019.0     MICS 2019  \n",
            "\n",
            "[202 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import pandas as pd\n",
        "\n",
        "def extract_table_from_pdf(pdf_file, output_excel_file):\n",
        "    try:\n",
        "        # Open the PDF file\n",
        "        with pdfplumber.open(pdf_file) as pdf:\n",
        "            for i, page in enumerate(pdf.pages):\n",
        "                # Extract tables from each page\n",
        "                tables = page.extract_tables()\n",
        "\n",
        "                # Process each table found on the page\n",
        "                for table_num, table in enumerate(tables):\n",
        "                    # Convert the table to a DataFrame\n",
        "                    df = pd.DataFrame(table[1:], columns=table[0])\n",
        "                    print(f\"\\nTable {table_num + 1} from Page {i + 1}:\")\n",
        "                    print(df)\n",
        "\n",
        "                    # Save each table to Excel (appending tables from different pages)\n",
        "                    with pd.ExcelWriter(output_excel_file, engine='openpyxl', mode='a') as writer:\n",
        "                        df.to_excel(writer, sheet_name=f\"Page_{i + 1}_Table_{table_num + 1}\", index=False)\n",
        "        print(f\"\\nAll tables have been extracted and saved to '{output_excel_file}'.\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{pdf_file}' was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Specify the input PDF and output Excel file\n",
        "file_path = \"Child_Labour_Marriage.pdf\"\n",
        "output_excel_path = \"extracted_data.xlsx\"\n",
        "\n",
        "# Extract tables from the PDF\n",
        "extract_table_from_pdf(pdf_file_path, output_excel_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQBWP3tIeMQG",
        "outputId": "f5c13667-416b-4d8a-c797-30f3aa305d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "All tables have been extracted and saved to 'extracted_data.xlsx'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "def insert_data_to_sqlite(file_path, db_name, table_name):\n",
        "    try:\n",
        "        # Step 1: Load the data into a Pandas DataFrame\n",
        "        data = pd.read_excel(file_path)\n",
        "        print(\"Data Loaded Successfully:\")\n",
        "        print(data.head())\n",
        "\n",
        "        # Step 2: Connect to SQLite database (or create it if it doesn't exist)\n",
        "        conn = sqlite3.connect(db_name)\n",
        "        print(f\"\\nConnected to SQLite database: {db_name}\")\n",
        "\n",
        "        # Step 3: Insert data into the SQLite database\n",
        "        data.to_sql(table_name, conn, if_exists='replace', index=False)\n",
        "        print(f\"\\nData has been inserted into the table '{table_name}'.\")\n",
        "\n",
        "        # Step 4: Verify by querying the table\n",
        "        query = f\"SELECT * FROM {table_name} LIMIT 5;\"\n",
        "        result = pd.read_sql(query, conn)\n",
        "        print(\"\\nSample Data from SQLite Database:\")\n",
        "        print(result)\n",
        "\n",
        "        # Close the database connection\n",
        "        conn.close()\n",
        "        print(\"\\nSQLite database connection closed.\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{file_path}' was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Specify the input file, database name, and table name\n",
        "excel_file = \"Child_Labour_Marriage.xlsx\"\n",
        "database_name = \"child_data.db\"\n",
        "table_name = \"ChildLabourAndMarriage\"\n",
        "\n",
        "# Call the function to insert data into SQLite\n",
        "insert_data_to_sqlite(excel_file, database_name, table_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M52mGrY3kjJj",
        "outputId": "28c4066b-f627-4b79-96a4-4acbe85928d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Loaded Successfully:\n",
            "      Country   Female Married by 15  Female Married by 18  Reference year  \\\n",
            "0  Afghanistan                   4.0                  28.0          2017.0   \n",
            "1      Albania                   1.0                  12.0          2018.0   \n",
            "2      Algeria                   0.0                   3.0          2013.0   \n",
            "3      Andorra                   NaN                   NaN             NaN   \n",
            "4       Angola                   8.0                  30.0          2016.0   \n",
            "\n",
            "    Data source  Male Married by 18  Male Reference year Data source.1  \n",
            "0  ALCS 2016-17                 7.0               2015.0      DHS 2015  \n",
            "1   DHS 2017-18                 1.0               2018.0   DHS 2017-18  \n",
            "2  MICS 2012-13                 NaN                  NaN           NaN  \n",
            "3           NaN                 NaN                  NaN           NaN  \n",
            "4   DHS 2015-16                 6.0               2016.0   DHS 2015-16  \n",
            "\n",
            "Connected to SQLite database: child_data.db\n",
            "\n",
            "Data has been inserted into the table 'ChildLabourAndMarriage'.\n",
            "\n",
            "Sample Data from SQLite Database:\n",
            "      Country   Female Married by 15  Female Married by 18  Reference year  \\\n",
            "0  Afghanistan                   4.0                  28.0          2017.0   \n",
            "1      Albania                   1.0                  12.0          2018.0   \n",
            "2      Algeria                   0.0                   3.0          2013.0   \n",
            "3      Andorra                   NaN                   NaN             NaN   \n",
            "4       Angola                   8.0                  30.0          2016.0   \n",
            "\n",
            "    Data source  Male Married by 18  Male Reference year Data source.1  \n",
            "0  ALCS 2016-17                 7.0               2015.0      DHS 2015  \n",
            "1   DHS 2017-18                 1.0               2018.0   DHS 2017-18  \n",
            "2  MICS 2012-13                 NaN                  NaN          None  \n",
            "3          None                 NaN                  NaN          None  \n",
            "4   DHS 2015-16                 6.0               2016.0   DHS 2015-16  \n",
            "\n",
            "SQLite database connection closed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# File paths\n",
        "input_file = \"Child_Labour_Marriage.xlsx\"\n",
        "output_file = \"Cleaned_Child_Labour_Marriagedata.xlsx\"\n",
        "\n",
        "def clean_excel_file(input_file, output_file):\n",
        "    try:\n",
        "        # Check if the file exists\n",
        "        if not os.path.exists(input_file):\n",
        "            print(f\"Error: File '{input_file}' not found!\")\n",
        "            return\n",
        "\n",
        "        # Load the Excel file into a DataFrame\n",
        "        print(\"Loading the Excel file...\")\n",
        "        df = pd.read_excel(input_file)\n",
        "\n",
        "        # Display initial data information\n",
        "        print(\"\\nInitial Dataset Information:\")\n",
        "        print(df.info())\n",
        "\n",
        "        # Drop duplicate rows\n",
        "        print(\"\\nRemoving duplicate rows...\")\n",
        "        df.drop_duplicates(inplace=True)\n",
        "\n",
        "        # Handle missing values\n",
        "        print(\"\\nHandling missing values...\")\n",
        "        df.fillna(value=\"Unknown\", inplace=True)\n",
        "\n",
        "        # Rename columns for consistency\n",
        "        print(\"\\nRenaming columns for consistency...\")\n",
        "        df.columns = [col.strip().replace(\" \", \"_\").lower() for col in df.columns]\n",
        "\n",
        "        # Standardize data formats (e.g., dates, text cases)\n",
        "        if \"date\" in df.columns:\n",
        "            print(\"\\nStandardizing date formats...\")\n",
        "            df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
        "\n",
        "        if \"age\" in df.columns:\n",
        "            print(\"\\nConverting age column to numeric...\")\n",
        "            df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
        "\n",
        "        # Save cleaned data to a new Excel file\n",
        "        print(f\"\\nSaving cleaned data to '{output_file}'...\")\n",
        "        df.to_excel(output_file, index=False)\n",
        "        print(\"Data cleanup completed successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Execute the script\n",
        "if __name__ == \"__main__\":\n",
        "    clean_excel_file(input_file, output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnFZRGsBrISb",
        "outputId": "2eb2d73e-7992-4bb5-f955-f5ff08047d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the Excel file...\n",
            "\n",
            "Initial Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 202 entries, 0 to 201\n",
            "Data columns (total 8 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Country               202 non-null    object \n",
            " 1   Female Married by 15  128 non-null    float64\n",
            " 2   Female Married by 18  128 non-null    float64\n",
            " 3   Reference year        128 non-null    float64\n",
            " 4   Data source           128 non-null    object \n",
            " 5   Male Married by 18    95 non-null     float64\n",
            " 6   Male Reference year   95 non-null     float64\n",
            " 7   Data source.1         95 non-null     object \n",
            "dtypes: float64(5), object(3)\n",
            "memory usage: 12.8+ KB\n",
            "None\n",
            "\n",
            "Removing duplicate rows...\n",
            "\n",
            "Handling missing values...\n",
            "\n",
            "Renaming columns for consistency...\n",
            "\n",
            "Saving cleaned data to 'Cleaned_Child_Labour_Marriagedata.xlsx'...\n",
            "Data cleanup completed successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-fbcff949f8ca>:29: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.fillna(value=\"Unknown\", inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# File path\n",
        "input_file = \"Child_Labour_Marriage.xlsx\"\n",
        "\n",
        "def analyze_duplicates_and_missing_data(file_name):\n",
        "    try:\n",
        "        # Check if the file exists\n",
        "        if not os.path.exists(file_name):\n",
        "            print(f\"Error: File '{file_name}' not found!\")\n",
        "            return\n",
        "\n",
        "        # Load the Excel file into a DataFrame\n",
        "        print(\"Loading the Excel file...\")\n",
        "        df = pd.read_excel(file_name)\n",
        "\n",
        "        # Display dataset information\n",
        "        print(\"\\nDataset Information:\")\n",
        "        print(df.info())\n",
        "\n",
        "        # Check for duplicate rows\n",
        "        duplicate_count = df.duplicated().sum()\n",
        "        print(f\"\\nNumber of duplicate rows: {duplicate_count}\")\n",
        "\n",
        "        if duplicate_count > 0:\n",
        "            print(\"\\nDuplicate rows preview:\")\n",
        "            print(df[df.duplicated()])\n",
        "\n",
        "        # Check for missing data\n",
        "        print(\"\\nChecking for missing data...\")\n",
        "        missing_data_summary = df.isnull().sum()\n",
        "        total_missing = missing_data_summary.sum()\n",
        "        print(\"\\nMissing Data Summary (per column):\")\n",
        "        print(missing_data_summary)\n",
        "\n",
        "        print(f\"\\nTotal missing values in the dataset: {total_missing}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Execute the analysis\n",
        "if __name__ == \"__main__\":\n",
        "    analyze_duplicates_and_missing_data(input_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M9bcfR0tDA5",
        "outputId": "440ecfec-26c3-45f7-a0b4-be9844bc6d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the Excel file...\n",
            "\n",
            "Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 202 entries, 0 to 201\n",
            "Data columns (total 8 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Country               202 non-null    object \n",
            " 1   Female Married by 15  128 non-null    float64\n",
            " 2   Female Married by 18  128 non-null    float64\n",
            " 3   Reference year        128 non-null    float64\n",
            " 4   Data source           128 non-null    object \n",
            " 5   Male Married by 18    95 non-null     float64\n",
            " 6   Male Reference year   95 non-null     float64\n",
            " 7   Data source.1         95 non-null     object \n",
            "dtypes: float64(5), object(3)\n",
            "memory usage: 12.8+ KB\n",
            "None\n",
            "\n",
            "Number of duplicate rows: 0\n",
            "\n",
            "Checking for missing data...\n",
            "\n",
            "Missing Data Summary (per column):\n",
            "Country                   0\n",
            "Female Married by 15     74\n",
            "Female Married by 18     74\n",
            "Reference year           74\n",
            "Data source              74\n",
            "Male Married by 18      107\n",
            "Male Reference year     107\n",
            "Data source.1           107\n",
            "dtype: int64\n",
            "\n",
            "Total missing values in the dataset: 617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# File paths\n",
        "input_file = \"Child_Labour_Marriage.xlsx\"\n",
        "output_file = \"Cleaned_Child_Labour_Marriage.xlsx\"\n",
        "\n",
        "def clean_dataset(file_name, output_file):\n",
        "    try:\n",
        "        # Check if the file exists\n",
        "        if not os.path.exists(file_name):\n",
        "            print(f\"Error: File '{file_name}' not found!\")\n",
        "            return\n",
        "\n",
        "        # Load the Excel file into a DataFrame\n",
        "        print(\"Loading the Excel file...\")\n",
        "        df = pd.read_excel(file_name)\n",
        "\n",
        "        # Strip column names to remove leading/trailing spaces\n",
        "        df.columns = df.columns.str.strip()\n",
        "\n",
        "        # Display available columns\n",
        "        print(\"\\nAvailable Columns in Dataset:\")\n",
        "        print(df.columns.tolist())\n",
        "\n",
        "        # Identify missing data\n",
        "        print(\"\\nMissing Data per Column:\")\n",
        "        print(df.isnull().sum())\n",
        "\n",
        "        # Define critical columns for cleanup\n",
        "        critical_columns = [\"Country\", \"Female Married by 15\", \"Reference year\"]\n",
        "\n",
        "        # Check if critical columns exist in the dataset\n",
        "        for col in critical_columns:\n",
        "            if col not in df.columns:\n",
        "                raise KeyError(f\"Column '{col}' not found in the dataset!\")\n",
        "\n",
        "        # Drop rows with missing values in critical columns\n",
        "        print(f\"\\nDropping rows with missing values in columns: {critical_columns}\")\n",
        "        df.dropna(subset=critical_columns, inplace=True)\n",
        "\n",
        "        # Identify and remove duplicate rows\n",
        "        print(\"\\nChecking for duplicate rows...\")\n",
        "        duplicates = df.duplicated().sum()\n",
        "        print(f\"Number of duplicate rows: {duplicates}\")\n",
        "        if duplicates > 0:\n",
        "            print(\"Removing duplicate rows...\")\n",
        "            df.drop_duplicates(inplace=True)\n",
        "\n",
        "        # Final dataset information\n",
        "        print(\"\\nFinal Dataset Information:\")\n",
        "        print(df.info())\n",
        "\n",
        "        # Save the cleaned dataset\n",
        "        print(f\"\\nSaving cleaned data to '{output_file}'...\")\n",
        "        df.to_excel(output_file, index=False)\n",
        "        print(\"Data cleanup completed successfully!\")\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"KeyError: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Execute the cleanup\n",
        "if __name__ == \"__main__\":\n",
        "    clean_dataset(input_file, output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwt3dj6quagK",
        "outputId": "6e29c45c-2cf0-4fc9-ef88-111392d7556e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the Excel file...\n",
            "\n",
            "Available Columns in Dataset:\n",
            "['Country', 'Female Married by 15', 'Female Married by 18', 'Reference year', 'Data source', 'Male Married by 18', 'Male Reference year', 'Data source.1']\n",
            "\n",
            "Missing Data per Column:\n",
            "Country                   0\n",
            "Female Married by 15     74\n",
            "Female Married by 18     74\n",
            "Reference year           74\n",
            "Data source              74\n",
            "Male Married by 18      107\n",
            "Male Reference year     107\n",
            "Data source.1           107\n",
            "dtype: int64\n",
            "\n",
            "Dropping rows with missing values in columns: ['Country', 'Female Married by 15', 'Reference year']\n",
            "\n",
            "Checking for duplicate rows...\n",
            "Number of duplicate rows: 0\n",
            "\n",
            "Final Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 128 entries, 0 to 201\n",
            "Data columns (total 8 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Country               128 non-null    object \n",
            " 1   Female Married by 15  128 non-null    float64\n",
            " 2   Female Married by 18  128 non-null    float64\n",
            " 3   Reference year        128 non-null    float64\n",
            " 4   Data source           128 non-null    object \n",
            " 5   Male Married by 18    95 non-null     float64\n",
            " 6   Male Reference year   95 non-null     float64\n",
            " 7   Data source.1         95 non-null     object \n",
            "dtypes: float64(5), object(3)\n",
            "memory usage: 9.0+ KB\n",
            "None\n",
            "\n",
            "Saving cleaned data to 'Cleaned_Child_Labour_Marriage.xlsx'...\n",
            "Data cleanup completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "# File paths\n",
        "input_file = \"Child_Labour_Marriage.xlsx\"\n",
        "output_file = \"Cleaned_Child_Labour_Marriage.xlsx\"\n",
        "\n",
        "def clean_text_column(column):\n",
        "    \"\"\"\n",
        "    Cleans a text column by:\n",
        "    - Removing line breaks (\\n, \\r).\n",
        "    - Stripping extra spaces (leading, trailing, and multiple spaces).\n",
        "    - Removing special characters (non-alphanumeric except for spaces).\n",
        "    \"\"\"\n",
        "    return column.apply(lambda x: re.sub(r'\\s+', ' ', re.sub(r'[^\\w\\s]', '', str(x).replace('\\n', '').replace('\\r', '').strip())) if pd.notnull(x) else x)\n",
        "\n",
        "def clean_dataset(file_name, output_file):\n",
        "    try:\n",
        "        # Check if the file exists\n",
        "        if not os.path.exists(file_name):\n",
        "            print(f\"Error: File '{file_name}' not found!\")\n",
        "            return\n",
        "\n",
        "        # Load the Excel file into a DataFrame\n",
        "        print(\"Loading the Excel file...\")\n",
        "        df = pd.read_excel(file_name)\n",
        "\n",
        "        # Strip column names to remove leading/trailing spaces\n",
        "        df.columns = df.columns.str.strip()\n",
        "\n",
        "        # Display available columns\n",
        "        print(\"\\nAvailable Columns in Dataset:\")\n",
        "        print(df.columns.tolist())\n",
        "\n",
        "        # Clean each text column\n",
        "        print(\"\\nCleaning text columns...\")\n",
        "        for col in df.select_dtypes(include=['object']).columns:\n",
        "            print(f\"Cleaning column: {col}\")\n",
        "            df[col] = clean_text_column(df[col])\n",
        "\n",
        "        # Save the cleaned dataset\n",
        "        print(f\"\\nSaving cleaned data to '{output_file}'...\")\n",
        "        df.to_excel(output_file, index=False)\n",
        "        print(\"Data cleanup completed successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Execute the cleanup\n",
        "if __name__ == \"__main__\":\n",
        "    clean_dataset(input_file, output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_JjWKBo9phg",
        "outputId": "754aa0fd-6b17-48fb-e152-344fe8e1dcc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the Excel file...\n",
            "\n",
            "Available Columns in Dataset:\n",
            "['Country', 'Female Married by 15', 'Female Married by 18', 'Reference year', 'Data source', 'Male Married by 18', 'Male Reference year', 'Data source.1']\n",
            "\n",
            "Cleaning text columns...\n",
            "Cleaning column: Country\n",
            "Cleaning column: Data source\n",
            "Cleaning column: Data source.1\n",
            "\n",
            "Saving cleaned data to 'Cleaned_Child_Labour_Marriage.xlsx'...\n",
            "Data cleanup completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install agate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9M9pF0M_I2I",
        "outputId": "889e2c68-8bd4-467d-cb3a-7496d5b90fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting agate\n",
            "  Downloading agate-1.12.0-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: Babel>=2.0 in /usr/local/lib/python3.11/dist-packages (from agate) (2.16.0)\n",
            "Collecting isodate>=0.5.4 (from agate)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting leather>=0.3.2 (from agate)\n",
            "  Downloading leather-0.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting parsedatetime!=2.5,>=2.1 (from agate)\n",
            "  Downloading parsedatetime-2.6-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: python-slugify>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from agate) (8.0.4)\n",
            "Collecting pytimeparse>=1.1.5 (from agate)\n",
            "  Downloading pytimeparse-1.1.8-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify>=1.2.1->agate) (1.3)\n",
            "Downloading agate-1.12.0-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading leather-0.4.0-py2.py3-none-any.whl (30 kB)\n",
            "Downloading parsedatetime-2.6-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytimeparse-1.1.8-py2.py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: pytimeparse, parsedatetime, leather, isodate, agate\n",
            "Successfully installed agate-1.12.0 isodate-0.7.2 leather-0.4.0 parsedatetime-2.6 pytimeparse-1.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import agate\n",
        "import pandas as pd\n",
        "\n",
        "# File paths\n",
        "input_file = \"Child_Labour_Marriage.xlsx\"\n",
        "\n",
        "def load_and_explore_with_agate(file_name):\n",
        "    try:\n",
        "        # Check if the file exists\n",
        "        if not os.path.exists(file_name):\n",
        "            print(f\"Error: File '{file_name}' not found!\")\n",
        "            return\n",
        "\n",
        "        # Load Excel file into pandas first (as agate doesn't directly support Excel files)\n",
        "        print(\"Loading the Excel file...\")\n",
        "        df = pd.read_excel(file_name)\n",
        "\n",
        "        # Strip column names to remove leading/trailing spaces\n",
        "        df.columns = df.columns.str.strip()\n",
        "\n",
        "        # Save the DataFrame to a CSV for agate compatibility\n",
        "        temp_csv_file = \"temp_data.csv\"\n",
        "        df.to_csv(temp_csv_file, index=False)\n",
        "\n",
        "        # Load the CSV file into an agate table\n",
        "        table = agate.Table.from_csv(temp_csv_file)\n",
        "\n",
        "        # Explore the table\n",
        "        print(\"\\nExploring the Agate Table:\")\n",
        "        print(f\"Number of rows: {len(table.rows)}\")\n",
        "        print(f\"Column names: {table.column_names}\")\n",
        "        print(\"\\nData Types:\")\n",
        "        for col_name, col_type in zip(table.column_names, table.column_types):\n",
        "            print(f\"- {col_name}: {col_type}\")\n",
        "\n",
        "        # Find statistical correlation for numeric columns\n",
        "        print(\"\\nPerforming Correlation Analysis...\")\n",
        "        numeric_columns = [col for col in table.column_names if isinstance(table.columns[col].data_type, agate.Number)]\n",
        "        if len(numeric_columns) < 2:\n",
        "            print(\"Not enough numeric columns for correlation analysis.\")\n",
        "        else:\n",
        "            for i, col1 in enumerate(numeric_columns):\n",
        "                for col2 in numeric_columns[i+1:]:\n",
        "                    correlation = table.compute([\n",
        "                        ('correlation', agate.PercentChange(col1, col2))\n",
        "                    ])\n",
        "                    print(f\"Correlation between '{col1}' and '{col2}': {correlation}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Execute the function\n",
        "if __name__ == \"__main__\":\n",
        "    load_and_explore_with_agate(input_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUBcwPc4-b2Q",
        "outputId": "de7184f4-7d19-4363-cba8-48500aa4fb08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the Excel file...\n",
            "\n",
            "Exploring the Agate Table:\n",
            "Number of rows: 202\n",
            "Column names: ('Country', 'Female Married by 15', 'Female Married by 18', 'Reference year', 'Data source', 'Male Married by 18', 'Male Reference year', 'Data source.1')\n",
            "\n",
            "Data Types:\n",
            "- Country: <agate.data_types.text.Text object at 0x7f367761d250>\n",
            "- Female Married by 15: <agate.data_types.number.Number object at 0x7f367d7d9e50>\n",
            "- Female Married by 18: <agate.data_types.number.Number object at 0x7f367d7d9e50>\n",
            "- Reference year: <agate.data_types.number.Number object at 0x7f367d7d9e50>\n",
            "- Data source: <agate.data_types.text.Text object at 0x7f367761d250>\n",
            "- Male Married by 18: <agate.data_types.number.Number object at 0x7f367d7d9e50>\n",
            "- Male Reference year: <agate.data_types.number.Number object at 0x7f367d7d9e50>\n",
            "- Data source.1: <agate.data_types.text.Text object at 0x7f367761d250>\n",
            "\n",
            "Performing Correlation Analysis...\n",
            "An error occurred: [<class 'decimal.DivisionByZero'>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/agate/computations/percent_change.py:35: NullCalculationWarning: Column \"Female Married by 15\" contains nulls. These will be excluded from PercentChange calculation.\n",
            "  warn_null_calculation(self, before_column)\n",
            "/usr/local/lib/python3.11/dist-packages/agate/computations/percent_change.py:38: NullCalculationWarning: Column \"Female Married by 18\" contains nulls. These will be excluded from PercentChange calculation.\n",
            "  warn_null_calculation(self, after_column)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# File paths\n",
        "input_file = \"Child_Labour_Marriage.xlsx\"\n",
        "\n",
        "def plot_corruption_vs_child_labour(file_name):\n",
        "    try:\n",
        "        # Load the dataset\n",
        "        print(\"Loading the dataset...\")\n",
        "        df = pd.read_excel(file_name)\n",
        "\n",
        "        # Strip column names to remove leading/trailing spaces\n",
        "        df.columns = df.columns.str.strip()\n",
        "\n",
        "        # Check if required columns exist\n",
        "        required_columns = ['Perceived Corruption Score', 'Child Labour Percentage']\n",
        "        for col in required_columns:\n",
        "            if col not in df.columns:\n",
        "                raise KeyError(f\"Column '{col}' is missing in the dataset!\")\n",
        "\n",
        "        # Drop rows with missing values in the relevant columns\n",
        "        df = df.dropna(subset=required_columns)\n",
        "\n",
        "        # Extract the relevant columns\n",
        "        corruption_scores = df['Perceived Corruption Score']\n",
        "        child_labour_percentages = df['Child Labour Percentage']\n",
        "\n",
        "        # Plot the scatter plot\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.scatter(corruption_scores, child_labour_percentages, color='blue', alpha=0.7, edgecolor='black')\n",
        "        plt.title('Perceived Corruption Scores vs. Child Labour Percentages', fontsize=14)\n",
        "        plt.xlabel('Perceived Corruption Score', fontsize=12)\n",
        "        plt.ylabel('Child Labour Percentage (%)', fontsize=12)\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Show the plot\n",
        "        print(\"Displaying the scatter plot...\")\n",
        "        plt.show()\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"KeyError: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Execute the plotting function\n",
        "if __name__ == \"__main__\":\n",
        "    plot_corruption_vs_child_labour(input_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MygETPpW_1iB",
        "outputId": "70e94d80-9001-45ca-936b-a970423ca8ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the dataset...\n",
            "KeyError: \"Column 'Perceived Corruption Score' is missing in the dataset!\"\n"
          ]
        }
      ]
    }
  ]
}